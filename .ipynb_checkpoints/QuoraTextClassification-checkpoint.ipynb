{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File 'Stats 131'/QuoraQuestions/train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-af6174ff469e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moriginal_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\'Stats 131\\'/QuoraQuestions/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moriginal_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'QuoraQuestions/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File 'Stats 131'/QuoraQuestions/train.csv does not exist"
     ]
    }
   ],
   "source": [
    "original_train = pd.read_csv('Stats 131/QuoraQuestions/train.csv')\n",
    "original_test = pd.read_csv('QuoraQuestions/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80810"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_train[original_train['target'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which babies are more sweeter to their parents? Dark skin babies or light skin babies?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].head()['question_text'][30] # definitively insincere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].head()['question_text'][110] # on the cusp - could be considered insincere bc \"blacks\" is not necessarily PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].head()['question_text'][114] # lascivious and this is borderline incest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which races have the smallest penis?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].head()['question_text'][115] # definitely insincere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How is it to have intimate relation with your cousin?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].tail()['question_text'][1306093] # part 2 - incest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do pakis smell of curry and shit?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].tail()['question_text'][1306099] # racist towards pakistani people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why is it when singers have lyrics about voices in their head, religious people say they hear god and anyone stating they are being targeted by voice to brain technology? Are they called delusional schizo?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train[original_train['target'] == 1].tail()['question_text'][1306094] # provocative and trying to make a statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_train1 = list(map(lambda x : x.lower().split(), original_train[original_train['target'] == 1]['question_text']))\n",
    "split_train0 = list(map(lambda x : x.lower().split(), original_train[original_train['target'] == 0]['question_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Has',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'become',\n",
       " 'the',\n",
       " 'largest',\n",
       " 'dictatorship',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Has', 'the', 'United', 'States', 'become']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "concatenated_split_train = list(itertools.chain.from_iterable(split_train))\n",
    "concatenated_split_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "s = stopwords.words('english')\n",
    "concatenated_split_train = list(filter(lambda x : x not in s, concatenated_split_train))  # filter out all stop words (e.g. pronouns, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Why       32669\n",
       "I         11235\n",
       "people    10864\n",
       "Is         8394\n",
       "How        7510\n",
       "What       6105\n",
       "Do         5654\n",
       "like       5638\n",
       "Trump      4701\n",
       "women      4636\n",
       "Are        4609\n",
       "think      3758\n",
       "If         3688\n",
       "many       3471\n",
       "get        3152\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(concatenated_split_train).value_counts()[:15] # top 15 words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features for Training/Testing Data\n",
    "Our input values will be constructed as follows:\n",
    "* Features = columns\n",
    "* Samples = rows\n",
    "\n",
    "Let's concatenate the questions from the training data and testing data so that we can create the features based on the entire dataset. If we were to do this for the training and testing datasets individually, this would cause errors when we try to predict values from our testing dataset due to different number of dimensions in the number of columns in train compared to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1362492L,)\n"
     ]
    }
   ],
   "source": [
    "# concatenate train and test\n",
    "import copy\n",
    "X = copy.deepcopy(original_train['question_text'])\n",
    "Z = copy.deepcopy(original_test['question_text'])\n",
    "X = X.append(Z)\n",
    "X= X.reset_index(drop = True)\n",
    "print X.shape # number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370\n",
      "0.0413727199866\n"
     ]
    }
   ],
   "source": [
    "print len(Z) # length of test dataset\n",
    "print float(len(Z))/len(X) # proportion of the entire dataset that is testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958627280013\n"
     ]
    }
   ],
   "source": [
    "print float(len(X) - len(Z))/len(X) # proportion of the dataset that is training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's split our training dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwgAAAC5CAIAAAADGY8NAAAabklEQVR42uzdDXBU1d3H8XOTdQOR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\nJDTDv4+X/K8yf39jXd//DwAA//9Ysh9EYhBO9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='datasplit.png')\n",
    "# this is how our data will be split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902757594173\n",
      "0.0558696858404\n"
     ]
    }
   ],
   "source": [
    "train_size = 1230000\n",
    "print float(train_size)/len(X) # first 90% will be train data\n",
    "\n",
    "valid_size = len(X) - len(Z)\n",
    "print float(valid_size)/len(X) -  float(train_size)/len(X) # the remaining ~6% will be validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, create features through word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gets word counts of all unique words in the dataset - Bag of Words Representation (order doesn't matter)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words = 'english') # remove stop_words (e.g. the, a, in, pronouns, etc.)\n",
    "X_train_counts = count_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1362492, 199138)\n"
     ]
    }
   ],
   "source": [
    "print X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1362492, 199138)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts word counts into word frequencies with values between 0 and 1 - this also normalizes the data\n",
    "# word frequencies are calculated by quora question not frequency across the entire dataset\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape # the shape here is the (num_samples, num_features) where num_features == unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did Quebec nationalists see their province as a nation in the 1960s?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] # initial format of question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x199138 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0] # 1 sample - the question converted into a vector of counts and then a vector of word frequencies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Classifier \n",
    "Note: I used a MultinomialNB Classifier since other classifiers have a much longer run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function displays the metrics for evaluation of the model.\n",
    "from sklearn import metrics\n",
    "def results(expected, actual):\n",
    "    not_equal = actual[actual != expected]\n",
    "    fn = not_equal[not_equal == 0] # false negatives\n",
    "    accuracy = metrics.accuracy_score(expected, actual)\n",
    "    recall = metrics.recall_score(expected, actual)\n",
    "    precision = metrics.precision_score(expected, actual)\n",
    "    harmonic_mean = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print 'Accuracy Score: ' + str(accuracy) # accuracy score based on our validation data \n",
    "    print 'Recall Score: ' + str(recall)\n",
    "    print 'Precision Score: ' + str(precision)\n",
    "    print 'Harmonic Mean: ' + str(harmonic_mean) + '\\n'\n",
    "    print 'Expected Insincere: ' + str(len(expected[expected == 1])) # insincere\n",
    "    print 'Actual Number Insincere: ' + str(len(actual[actual == 1])) # insincere\n",
    "    print 'Number of False Negatives: ' + str(len(fn))\n",
    "    print 'Actual Number Sincere: ' + str(len(actual[actual == 0])) # sincere\n",
    "    print 'Total: ' + str(len(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function fits the data to a model and yields fitted values from the model\n",
    "def model(alg, x, y, training_size, validation_size):\n",
    "    classifier = alg.fit(x[:training_size], y[:training_size]) \n",
    "    validation = classifier.predict(x[training_size:validation_size]) \n",
    "    predicted = classifier.predict(X_train_tfidf[validation_size:]) # no target data available\n",
    "    results(original_train['target'][training_size:validation_size], validation)\n",
    "    return validation, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function displays some of the sample questions and their predicted target values\n",
    "import numpy as np\n",
    "def display_samples(question_type, x_data, v_size, pred):\n",
    "    if question_type:\n",
    "        indices = np.where(pred == 1)\n",
    "    else: \n",
    "        indices = np.where(pred == 0)\n",
    "    print 'Here are a few samples with their target values.'\n",
    "    count = 0\n",
    "    for i in list(indices[0]):\n",
    "        if count > 10: # display 10 samples\n",
    "            break\n",
    "        print x_data[v_size + i]\n",
    "        print pred[i] \n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model \n",
    "For the base model, let's set all target values to 0, where 0 is the class for sincere questions, since the majority of questions are sincere. You'll see that the number of insincere predicted values is 0. This is because we didn't train on any insincere values. Also, the recall and precision scores are all 0. This is because we did not train on any data where the target value == 1, so it's not possible to have a true positive (value == 1), which is the numerator of the recall and precision scores. \n",
    "* recall = TP / TP + FN\n",
    "* precision = TP / TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.937915451512\n",
      "Recall Score: 0.0\n",
      "Precision Score: 0.0\n",
      "Harmonic Mean: nan\n",
      "\n",
      "Expected Insincere: 4726\n",
      "Actual Number Insincere: 0\n",
      "Number of False Negatives: 4726\n",
      "Actual Number Sincere: 76122\n",
      "Total: 76122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "algorithm = MultinomialNB()\n",
    "y_base = list(copy.deepcopy(original_train['target'][:train_size]))\n",
    "y_base = list(map(lambda x: x*0, y_base))\n",
    "y_valid, y_pred = model(algorithm, X_train_tfidf, y_base, train_size, valid_size)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model With Observed Data\n",
    "Now, let's see how the model performs on our observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.94051653924\n",
      "Recall Score: 0.0778671180702\n",
      "Precision Score: 0.684014869888\n",
      "Harmonic Mean: 0.139817629179\n",
      "\n",
      "Expected Insincere: 4726\n",
      "Actual Number Insincere: 538\n",
      "Number of False Negatives: 4358\n",
      "Actual Number Sincere: 75584\n",
      "Total: 76122\n"
     ]
    }
   ],
   "source": [
    "algorithm = MultinomialNB()\n",
    "y_valid, y_pred = model(algorithm, X_train_tfidf, original_train['target'], train_size, valid_size) \n",
    "# we want all of the proportions below to be as close to 1 as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "Our recall score was pretty low. This means we had several false negatives - we predicted sincere when it was supposed to be insincere. Look at some of the sample questions that this was the case for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function displays questions which were predicted to be sincere but Quora deems them to be insincere \n",
    "def display_false_negatives(expected, actual, input_questions, index):\n",
    "    fn_indices = list(np.where((actual != expected) & (actual == 0))[0])\n",
    "    print np.take(list(input_questions), fn_indices)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did President Obama insert a sleeper agent in the White House right before he left office?\n"
     ]
    }
   ],
   "source": [
    "display_false_negatives(original_train['target'][train_size:valid_size], y_valid, X[train_size:valid_size], index = 0)\n",
    "# change the index to see different samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Results\n",
    "Let's see some of our samples from the testing data (includes input and output values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display insincere samples\n",
    "display_samples(1, X, valid_size, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display sincere samples\n",
    "display_samples(0, X, valid_size, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To improve performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: cross validate data by using training and testing on differnet chunks of the data\n",
    "* example: x = [1, 2, 3, 4, 5, 6, 7, 8, 9 , 10]\n",
    "    define train size = 2\n",
    "    run the model on  the following splits and compoare the \n",
    "    * train = x[0:8]; validation = x[8:10]\n",
    "    * train = x[1:9]; validation = [x[0], x[9]]\n",
    "    * train = x[2:10], validation = [x[0:2]]\n",
    "    * validation = [x[0], x[8]]; train = the rest\n",
    "    * validation = [x[1], x[4]]; train = the rest\n",
    "    * finish for all combinations\n",
    "\n",
    "The final accuracy = the average of the accuracies from each split.\n",
    "It's the same for recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: create features with n-grams (instead of using words as feature columns, use phrases with n words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: try different models if the runtime isn't too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To explore and visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: create word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: show histogram of word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: group questions into themes: e.g. racism, sexism, sexuality, religious intolerance, \n",
    "# prejudice towards immigrants, unproductive political criticism\n",
    "# Visualize this data\n",
    "# Show percentages of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: show percentage of each question type: e.g. why, how, what, do\n",
    "# Also, compare these percentages in sincere vs insincere questons\n",
    "# It seems that the top question type is \"why\"\n",
    "# What does this say about the way we obtain knowledge? Why is the \"why\" question the most common question?\n",
    "    # Why assumes that the questioner believes the statement to be true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# larger question for discussion section: although people make such discriminatory remarks, should we censor the online public?\n",
    "# what are the implications of online censorship? \n",
    "    # Argument against censorship: people have dark, deep thoughts that may be contentious but perhaps they truly believe \n",
    "    # those thoughts and are genuinely curious. The online public could offer a medium to express and discuss those thoughts. \n",
    "    # One key advantage of online forums is the option to be anonymous, which makes one more open to share dark ideas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
